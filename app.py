# -*- coding: utf-8 -*-
"""IBM_LLM (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dbemCQ9E9QM5FsUmnjpBpOwB7A1iOU8h
"""

#LangChain 패키지 설치
# !pip install -U "langchain>=0.3,<0.4" | tail -n 1
# !pip install -U "langchain_ibm>=0.3,<0.4" | tail -n 1
# pip install gradio

#api키, project Id 등 기본 credentials 설정
import getpass
from ibm_watsonx_ai import Credentials
from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
from dotenv import load_dotenv
import os

load_dotenv()

load_a_k = os.getenv('api_key')
load_p_k = os.getenv('project_id')

credentials = Credentials(
    url="https://us-south.ml.cloud.ibm.com",
    api_key=load_a_k,
)
project_id = load_p_k

#IBM Cloud Connect
from ibm_watsonx_ai import APIClient

api_client = APIClient(credentials=credentials, project_id=project_id)

#LLM Parameter 설정
from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods

parameters = {
    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE.value,
    GenParams.MAX_NEW_TOKENS: 1000,
    GenParams.MIN_NEW_TOKENS: 1,
    GenParams.TEMPERATURE: 0.5,
    GenParams.TOP_K: 50,
    GenParams.TOP_P: 1
}

# 사용 모델 선택
model_id_1 = "ibm/granite-3-8b-instruct"
model_id_2 = "ibm/granite-3-2-8b-instruct-preview-rc"

#LLM 모델 기본 설정
from langchain_ibm import WatsonxLLM

flan_ul2_llm = WatsonxLLM(
    model_id=model_id_1,
    url=credentials["url"],
    apikey=credentials["apikey"],
    project_id=project_id,
    params=parameters
)

flan_t5_llm = WatsonxLLM(
    model_id=model_id_2,
    url=credentials["url"],
    apikey=credentials["apikey"],
    project_id=project_id
    )

from langchain_core.prompts import PromptTemplate
from langchain.chains import LLMChain

# 프롬프트 생성
question1 = PromptTemplate(
    input_variables=["question"],
    template="{question}",
)

#LLM Chain
flan_to_t5 = LLMChain(llm=flan_t5_llm, prompt=question1, output_key='answer')

import gradio as gr
def update(a):
    text = 'Answer the following question:' + a 
    ans = flan_to_t5.invoke({text})
    return f"{ans['answer']}"

with gr.Blocks() as iface:
    gr.Markdown("IBM 인턴쉽 테스트 코드")
    with gr.Row():
        inp = gr.Textbox(placeholder="지문을 입력하시오")
        out = gr.Textbox()
    btn = gr.Button("제출")

    btn.click(fn=update, inputs=inp, outputs=out)

iface.launch(share=True)
